device = cpu
simulation_speed = 1
state_size = 44
action_size = 7
hidden_size = 512
input_size = 44
batch_size = 128
buffer_size = 1000000
discount_factor = 0.99
learning_rate = 0.003
tau = 0.003
step_time = 0.01
loss_function = <function smooth_l1_loss at 0x7f1fe78b83a0>
epsilon = 1.0
epsilon_decay = 0.9995
epsilon_minimum = 0.05
reward_function = C
backward_enabled = False
stacking_enabled = False
stack_depth = 2
frame_skip = 1
networks = [Actor(
  (fa1): Linear(in_features=44, out_features=512, bias=True)
  (fa2): Linear(in_features=512, out_features=512, bias=True)
  (fa3): Linear(in_features=512, out_features=7, bias=True)
), Actor(
  (fa1): Linear(in_features=44, out_features=512, bias=True)
  (fa2): Linear(in_features=512, out_features=512, bias=True)
  (fa3): Linear(in_features=512, out_features=7, bias=True)
)]
iteration = 0
possible_actions = [[0.3, -1.0], [0.4, -0.5], [0.5, -0.25], [1.0, 0.0], [0.5, 0.25], [0.4, 0.5], [0.3, 1.0]]
target_update_frequency = 1000
actor_optimizer = AdamW (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.003
    weight_decay: 0.01
)

